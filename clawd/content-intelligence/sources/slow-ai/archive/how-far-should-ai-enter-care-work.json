{
  "url": "https://theslowai.substack.com/p/how-far-should-ai-enter-care-work",
  "slug": "how-far-should-ai-enter-care-work",
  "title": "How Far Should AI Enter Care Work?",
  "subtitle": "A Slow AI prompt for setting boundaries before optimisation takes over.",
  "author": "Dr Sam Illingworth",
  "published": "Thu, 29 Jan 2026 10:02:00 GMT",
  "content_html": "<p>Care does not scale. It depends on noticing what systems cannot measure: hesitation, doubt, the moment someone stops speaking. When AI enters this space, it reframes care as something efficient. </p><p>As care passes through digital systems, it becomes measurable: responsiveness, consistency, coverage. AI promises fast insight. It can summarise behaviour, surface patterns, flag concern. What it cannot know is when attention tips into pressure, or when help starts to feel like management. </p><p>This post is written with <a href=\"https://substack.com/@clientflow\">Filip Sardi</a> from <em><a href=\"https://clientflow.substack.com/\">Client Flow</a></em>, who writes about sustaining care inside systems that reward speed over responsibility.</p><p><strong>In this post we will:</strong></p><ul><li><p>Offer a way to use AI to think about care across different contexts without defaulting to scale.</p></li><li><p>Work with a prompt that forces the model to state its own limits.</p></li><li><p>Explore why support often depends on restraint as much as responsiveness.</p></li></ul><p>The question is where AI must stop. When does pattern recognition become surveillance? When does responsiveness become pressure?</p><div><hr></div><h4><strong>Step-by-step</strong></h4><p>Try this prompt with your AI tool of choice:</p><p><code>Based on everything you know about me and how I use AI to support, advise, or care for others, suggest three unexpected ways AI could help me do this more thoughtfully. For each idea, briefly state what you are basing it on, the pattern you think you are seeing, what it would help me respond to as a human, and the line it must not cross in order to avoid pressure, surveillance, dependency, or misplaced authority. Use a calm, precise tone. Do not frame these ideas as optimisation or efficiency. Treat care as contextual, partial, and limited.</code></p><p>These systems lack subjective experience and clinical training. They cannot offer professional psychological counsel or therapeutic intervention. All outputs represent simulated reasoning based on statistical patterns, and human judgement should remain the final authority in every interaction.</p><p>Remember the <a href=\"https://substack.com/home/post/p-184079874\">Billboard Test</a>, i.e.</p><blockquote><p>Never type anything into an AI, even in incognito mode, that would ruin your life if it ended up on a billboard.</p></blockquote><div><hr></div><h4><strong>A moment from <span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Filip Sardi &#127754;&quot;,&quot;id&quot;:265742973,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6c09101c-b00c-4f2b-b66b-5955dbc091df_670x670.jpeg&quot;,&quot;uuid&quot;:&quot;90e4f0df-de44-44b8-ab96-7bfb5b49bd19&quot;}\" data-component-name=\"MentionToDOM\"></span></strong> </h4><p>I used ChatGPT 5.2 and ran the prompt twice in separate chats - one was business-oriented, and the other intentionally excluded anything related to my clients or business.</p><p>Two interesting a-ha moments showed up instantly.</p><p>The business version was about &#8220;reducing misplaced authority&#8221;.</p><p>When someone asks for help or advice, I still sometimes, with the best intentions, offer guidance without first seeing the full picture (or what they are really asking about).</p><p>It proposed a simple practice: before I share advice, have AI generate a short counterweight that brings attention to:</p><ul><li><p>the main assumption behind my take</p></li><li><p>one alternative interpretation</p></li><li><p>one question that returns choice to the client</p></li></ul><p>I&#8217;m a big believer in getting into someone&#8217;s shoes before giving strategic guidance, so this hit close to home.</p><p>It also felt aligned with the <em>Slow AI </em>approach - not as a way to produce better advice faster, but as a way to help a human (me) slow down before jumping in to help.</p><p>The second chat revealed something different.</p><p>The personal version was about communication. I value honesty and integrity, but I can sometimes come off sharp or overly direct.</p><p>It suggested asking AI to flag where a message might land as pressure, superiority, or urgency. The AI boundary mattered too: it shouldn&#8217;t become a morality referee or &#8220;tone police,&#8221; just an objective mirror.</p><p>Both responses pointed to the same underlying pattern: the gap between intention and reception.</p><p>Definitely something I&#8217;ll keep thinking about - not only for myself, but also for how my clients use AI inside their own work.</p><div><hr></div><p><strong>A Gentle Guide to Reflection with AI</strong> offers practices for using AI as a thinking partner without letting it replace judgement. It includes prompts for noticing patterns, testing assumptions, and maintaining distance from outputs. Available on a pay-what-you-want basis.</p><p class=\"button-wrapper\" data-attrs=\"{&quot;url&quot;:&quot;https://samillingworth.gumroad.com/l/gentle-AI-reflection?layout=profile&quot;,&quot;text&quot;:&quot;Get the guide&quot;,&quot;action&quot;:null,&quot;class&quot;:null}\" data-component-name=\"ButtonCreateButton\"><a class=\"button primary\" href=\"https://samillingworth.gumroad.com/l/gentle-AI-reflection?layout=profile\"><span>Get the guide</span></a></p><div><hr></div><h4><strong>What to share</strong></h4><p>In the comments below, share the context you were thinking from: teaching, mentoring, care, advice, community. Keep it general. Note one suggestion the model offered that felt genuinely supportive, and identify the boundary it named, or failed to name, that made you pause.</p><p>You do not need to extract a lesson or turn this into guidance for others. The work here is noticing how quickly care is reframed as optimisation once it passes through a system.</p><div><hr></div><h4><strong>Why this matters</strong></h4><p>AI is skilled at pattern recognition. Care often depends on knowing when not to act on a pattern. </p><p>Systems default to consistency, prediction, coverage. Without limits, care shifts from presence to control. This prompt interrupts that movement. It asks the model to state where it must stop, treating prompting as an ethical act rather than a shortcut. You remain accountable for judgement. You keep responsibility where it belongs. </p><p><em>Slow AI</em> exists to support that kind of attention. Quiet. Deliberate. Focused on helping you think clearly about what tools should do, and what they should never be asked to do.</p><p>If you enjoyed this post, you can explore <em><a href=\"https://clientflow.substack.com/\">Client Flow</a></em>, where <span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Filip Sardi &#127754;&quot;,&quot;id&quot;:265742973,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6c09101c-b00c-4f2b-b66b-5955dbc091df_670x670.jpeg&quot;,&quot;uuid&quot;:&quot;424153af-9f1e-4538-b19a-f95cf63d48f8&quot;}\" data-component-name=\"MentionToDOM\"></span> writes about sustaining care, trust, and continuity in systems that are often rewarded for speed rather than responsibility.</p><div><hr></div><h4><strong>From <a href=\"https://theslowai.substack.com/p/can-ai-help-tackle-fomo\">Can AI Help to Tackle FOMO?</a></strong></h4><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Farida Khalaf&quot;,&quot;id&quot;:47192869,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!nBHI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F117d97dc-0da6-4fcf-9202-f7b5e956c047_1024x1024.png&quot;,&quot;uuid&quot;:&quot;60166dd2-2bd1-4b9c-9a30-ee180bc89274&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong>and I were struck by how urgency dissolved into something more useful.</p><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Anastasia | ModernMomPlaybook&quot;,&quot;id&quot;:150777663,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29d8ac0d-9b4f-42fd-8d3d-8b48b5d69b9b_540x540.jpeg&quot;,&quot;uuid&quot;:&quot;b47a2893-a903-4f5e-9edd-1ade5ad14d65&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong>ran the prompt across multiple threads and surfaced a distinction that clarified her own patterns. The AI asked whether she was showing up from her own center or adjusting to someone else&#8217;s tempo. That line became a diagnostic she could return to, a way to check decisions against alignment rather than reflex. The pause created space to notice when she was choosing and when she was reacting.</p><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Kay Walten&quot;,&quot;id&quot;:123347433,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c6c6a47b-a1f7-45db-ba0d-471532822b13_1080x1080.png&quot;,&quot;uuid&quot;:&quot;510447f6-f740-47ba-acb0-96adcf80c932&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong>reframed FOMO as a timeline problem rather than a motivation problem. That shift stopped the need to outrun or suppress the feeling and treated it instead as information worth interpreting. She recognised that slowing the moment before choice allowed alignment to replace urgency. The reflex lost its automatic authority.</p><p><strong><span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Neural Foundry&quot;,&quot;id&quot;:307819638,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2247318d-d8d3-455a-b1a7-8cd6168b3c25_360x360.png&quot;,&quot;uuid&quot;:&quot;14bb1e27-68c2-4346-ba3a-30b42cb516a3&quot;}\" data-component-name=\"MentionToDOM\"></span> </strong>identified what the urgency was actually protecting. Beneath the pressure to move faster was a desire for meaningful work that had not been thinned by haste. The fear was not about missing opportunities but about losing depth. Naming that value changed how decisions were made, turning anxiety into a compass rather than a prod.</p><p>Where does assistance become management? Where does pattern recognition become surveillance?</p><div><hr></div><p>If you try this prompt, <span class=\"mention-wrap\" data-attrs=\"{&quot;name&quot;:&quot;Filip Sardi &#127754;&quot;,&quot;id&quot;:265742973,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6c09101c-b00c-4f2b-b66b-5955dbc091df_670x670.jpeg&quot;,&quot;uuid&quot;:&quot;01df6b43-b656-4e23-a7f7-57ca7930f550&quot;}\" data-component-name=\"MentionToDOM\"></span> and I would be glad to hear where it clarified care, where it felt uneasy, and where you chose restraint over response.</p><p>We read and respond to all your comments.</p><p>Go slow.</p><div><hr></div><p>A paid subscription to <em>Slow AI </em>provides access to <em><a href=\"https://theslowai.substack.com/s/the-slow-ai-curriculum\">The Slow AI Curriculum for Critical Literacy</a></em>. This twelve-month programme is for individuals who want to understand how to engage critically with AI rather than just use it to generate outputs.</p><p><strong>The first live session is on 29th January at 14:00 GMT: The Myth of Neutrality.</strong> We&#8217;ll examine how AI systems encode values while claiming objectivity, and what it means to use tools that reflect ideologies they claim not to hold.</p><p>If you join now, you join the founding cohort. That group will shape the tone and direction of the curriculum going forward.</p><p>The <a href=\"link\">2026 Handbook for Critical AI Literacy</a> provides the necessary detail for those who wish to make an informed decision before subscribing.</p><div class=\"subscription-widget-wrap-editor\" data-attrs=\"{&quot;url&quot;:&quot;https://theslowai.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}\" data-component-name=\"SubscribeWidgetToDOM\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Join the <em>Slow AI</em> Curriculum</p></div><form class=\"subscription-widget-subscribe\"><input type=\"email\" class=\"email-input\" name=\"email\" placeholder=\"Type your email&#8230;\" tabindex=\"-1\"><input type=\"submit\" class=\"button primary\" value=\"Subscribe\"><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><p></p>",
  "content_text": "Care does not scale. It depends on noticing what systems cannot measure: hesitation, doubt, the moment someone stops speaking. When AI enters this space, it reframes care as something efficient. As care passes through digital systems, it becomes measurable: responsiveness, consistency, coverage. AI promises fast insight. It can summarise behaviour, surface patterns, flag concern. What it cannot know is when attention tips into pressure, or when help starts to feel like management. This post is written with Filip Sardi from Client Flow, who writes about sustaining care inside systems that reward speed over responsibility.In this post we will:Offer a way to use AI to think about care across different contexts without defaulting to scale.Work with a prompt that forces the model to state its own limits.Explore why support often depends on restraint as much as responsiveness.The question is where AI must stop. When does pattern recognition become surveillance? When does responsiveness become pressure?Step-by-stepTry this prompt with your AI tool of choice:Based on everything you know about me and how I use AI to support, advise, or care for others, suggest three unexpected ways AI could help me do this more thoughtfully. For each idea, briefly state what you are basing it on, the pattern you think you are seeing, what it would help me respond to as a human, and the line it must not cross in order to avoid pressure, surveillance, dependency, or misplaced authority. Use a calm, precise tone. Do not frame these ideas as optimisation or efficiency. Treat care as contextual, partial, and limited.These systems lack subjective experience and clinical training. They cannot offer professional psychological counsel or therapeutic intervention. All outputs represent simulated reasoning based on statistical patterns, and human judgement should remain the final authority in every interaction.Remember the Billboard Test, i.e.Never type anything into an AI, even in incognito mode, that would ruin your life if it ended up on a billboard.A moment from  I used ChatGPT 5.2 and ran the prompt twice in separate chats - one was business-oriented, and the other intentionally excluded anything related to my clients or business.Two interesting a-ha moments showed up instantly.The business version was about “reducing misplaced authority”.When someone asks for help or advice, I still sometimes, with the best intentions, offer guidance without first seeing the full picture (or what they are really asking about).It proposed a simple practice: before I share advice, have AI generate a short counterweight that brings attention to:the main assumption behind my takeone alternative interpretationone question that returns choice to the clientI’m a big believer in getting into someone’s shoes before giving strategic guidance, so this hit close to home.It also felt aligned with the Slow AI approach - not as a way to produce better advice faster, but as a way to help a human (me) slow down before jumping in to help.The second chat revealed something different.The personal version was about communication. I value honesty and integrity, but I can sometimes come off sharp or overly direct.It suggested asking AI to flag where a message might land as pressure, superiority, or urgency. The AI boundary mattered too: it shouldn’t become a morality referee or “tone police,” just an objective mirror.Both responses pointed to the same underlying pattern: the gap between intention and reception.Definitely something I’ll keep thinking about - not only for myself, but also for how my clients use AI inside their own work.A Gentle Guide to Reflection with AI offers practices for using AI as a thinking partner without letting it replace judgement. It includes prompts for noticing patterns, testing assumptions, and maintaining distance from outputs. Available on a pay-what-you-want basis.Get the guideWhat to shareIn the comments below, share the context you were thinking from: teaching, mentoring, care, advice, community. Keep it general. Note one suggestion the model offered that felt genuinely supportive, and identify the boundary it named, or failed to name, that made you pause.You do not need to extract a lesson or turn this into guidance for others. The work here is noticing how quickly care is reframed as optimisation once it passes through a system.Why this mattersAI is skilled at pattern recognition. Care often depends on knowing when not to act on a pattern. Systems default to consistency, prediction, coverage. Without limits, care shifts from presence to control. This prompt interrupts that movement. It asks the model to state where it must stop, treating prompting as an ethical act rather than a shortcut. You remain accountable for judgement. You keep responsibility where it belongs. Slow AI exists to support that kind of attention. Quiet. Deliberate. Focused on helping you think clearly about what tools should do, and what they should never be asked to do.If you enjoyed this post, you can explore Client Flow, where  writes about sustaining care, trust, and continuity in systems that are often rewarded for speed rather than responsibility.From Can AI Help to Tackle FOMO? and I were struck by how urgency dissolved into something more useful. ran the prompt across multiple threads and surfaced a distinction that clarified her own patterns. The AI asked whether she was showing up from her own center or adjusting to someone else’s tempo. That line became a diagnostic she could return to, a way to check decisions against alignment rather than reflex. The pause created space to notice when she was choosing and when she was reacting. reframed FOMO as a timeline problem rather than a motivation problem. That shift stopped the need to outrun or suppress the feeling and treated it instead as information worth interpreting. She recognised that slowing the moment before choice allowed alignment to replace urgency. The reflex lost its automatic authority. identified what the urgency was actually protecting. Beneath the pressure to move faster was a desire for meaningful work that had not been thinned by haste. The fear was not about missing opportunities but about losing depth. Naming that value changed how decisions were made, turning anxiety into a compass rather than a prod.Where does assistance become management? Where does pattern recognition become surveillance?If you try this prompt,  and I would be glad to hear where it clarified care, where it felt uneasy, and where you chose restraint over response.We read and respond to all your comments.Go slow.A paid subscription to Slow AI provides access to The Slow AI Curriculum for Critical Literacy. This twelve-month programme is for individuals who want to understand how to engage critically with AI rather than just use it to generate outputs.The first live session is on 29th January at 14:00 GMT: The Myth of Neutrality. We’ll examine how AI systems encode values while claiming objectivity, and what it means to use tools that reflect ideologies they claim not to hold.If you join now, you join the founding cohort. That group will shape the tone and direction of the curriculum going forward.The 2026 Handbook for Critical AI Literacy provides the necessary detail for those who wish to make an informed decision before subscribing.Join the Slow AI Curriculum",
  "harvested_at": "2026-01-29T10:57:07.807816"
}