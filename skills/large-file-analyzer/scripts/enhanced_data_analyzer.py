import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
import logging
from datetime import datetime

class EnhancedDataAnalyzer:
    def __init__(self, max_chunk_size: int = 1000):
        self.max_chunk_size = max_chunk_size
        self.logger = logging.getLogger(__name__)
    
    def analyze_marketing_data(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ä¸“é—¨é’ˆå¯¹è¥é”€/ä¼šå‘˜æ•°æ®çš„åˆ†æ"""
        analysis = {
            "user_demographics": self._analyze_demographics(df),
            "purchase_behavior": self._analyze_purchase_behavior(df),
            "engagement_metrics": self._analyze_engagement(df),
            "geographic_distribution": self._analyze_geography(df),
            "data_quality": self._assess_data_quality(df),
            "business_insights": self._generate_business_insights(df)
        }
        return analysis
    
    def _analyze_demographics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·äººå£ç»Ÿè®¡ä¿¡æ¯"""
        demographics = {}
        
        # æ€§åˆ«åˆ†æ
        gender_cols = [col for col in df.columns if 'æ€§åˆ«' in col or 'gender' in col.lower()]
        if gender_cols:
            gender_col = gender_cols[0]
            demographics['gender_distribution'] = df[gender_col].value_counts().to_dict()
        
        # å¹´é¾„åˆ†æ
        age_cols = [col for col in df.columns if 'å¹´é¾„' in col or 'age' in col.lower()]
        if age_cols:
            age_col = age_cols[0]
            age_series = pd.to_numeric(df[age_col], errors='coerce')
            demographics['age_analysis'] = {
                'mean': float(age_series.mean()),
                'median': float(age_series.median()),
                'std': float(age_series.std()),
                'min': float(age_series.min()),
                'max': float(age_series.max()),
                'outliers_count': len(self._detect_outliers(age_series))
            }
        
        # ä¼šå‘˜ç­‰çº§åˆ†æ
        tier_cols = [col for col in df.columns if 'ç­‰çº§' in col or 'tier' in col.lower() or 'level' in col.lower()]
        if tier_cols:
            tier_col = tier_cols[0]
            demographics['membership_tiers'] = df[tier_col].value_counts().to_dict()
        
        return demographics
    
    def _analyze_purchase_behavior(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æè´­ä¹°è¡Œä¸º"""
        behavior = {}
        
        # è´­ä¹°æ¸ é“åˆ†æ
        channel_cols = [col for col in df.columns if 'æ¸ é“' in col or 'channel' in col.lower()]
        if channel_cols:
            channel_col = channel_cols[0]
            behavior['purchase_channels'] = df[channel_col].value_counts().to_dict()
        
        # ç§¯åˆ†åˆ†æ
        points_cols = [col for col in df.columns if 'ç§¯åˆ†' in col or 'points' in col.lower()]
        if len(points_cols) >= 2:
            available_points = df[points_cols[0]]
            total_points = df[points_cols[1]]
            behavior['points_analysis'] = {
                'available_points_mean': float(pd.to_numeric(available_points, errors='coerce').mean()),
                'total_points_mean': float(pd.to_numeric(total_points, errors='coerce').mean()),
                'max_available_points': float(pd.to_numeric(available_points, errors='coerce').max()),
                'max_total_points': float(pd.to_numeric(total_points, errors='coerce').max()),
                'zero_points_users': int((pd.to_numeric(available_points, errors='coerce') == 0).sum())
            }
        
        return behavior
    
    def _analyze_engagement(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·å‚ä¸åº¦"""
        engagement = {}
        
        # æ´»è·ƒåº¦åˆ†æ
        activity_cols = [col for col in df.columns if 'æ´»è·ƒ' in col or 'activity' in col.lower() or 'ç§¯åˆ†äº§ç”Ÿ' in col]
        if activity_cols:
            activity_col = activity_cols[0]
            engagement['activity_status'] = df[activity_col].value_counts().to_dict()
        
        # æ³¨å†Œæ—¶é—´åˆ†æ
        registration_cols = [col for col in df.columns if 'æ³¨å†Œ' in col and ('æ—¶é—´' in col or 'date' in col.lower())]
        if registration_cols:
            reg_col = registration_cols[0]
            try:
                reg_dates = pd.to_datetime(df[reg_col], errors='coerce')
                engagement['registration_timeline'] = {
                    'earliest': reg_dates.min().isoformat() if pd.notna(reg_dates.min()) else None,
                    'latest': reg_dates.max().isoformat() if pd.notna(reg_dates.max()) else None,
                    'total_days_span': (reg_dates.max() - reg_dates.min()).days if pd.notna(reg_dates.min()) and pd.notna(reg_dates.max()) else None
                }
            except Exception as e:
                self.logger.warning(f"Could not parse registration dates: {e}")
        
        return engagement
    
    def _analyze_geography(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æåœ°ç†åˆ†å¸ƒ"""
        geography = {}
        
        # çœå¸‚åˆ†æ
        location_cols = [col for col in df.columns if 'çœ' in col or 'å¸‚' in col or 'location' in col.lower() or 'region' in col.lower()]
        if location_cols:
            loc_col = location_cols[0]
            # æå–çœä»½ï¼ˆå‡è®¾æ ¼å¼ä¸º"çœä»½åŸå¸‚..."ï¼‰
            provinces = df[loc_col].astype(str).str.split('çœ', expand=True)[0]
            geography['province_distribution'] = provinces.value_counts().head(10).to_dict()
        
        return geography
    
    def _assess_data_quality(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        quality = {
            'missing_values': {},
            'data_types': {},
            'potential_issues': []
        }
        
        # ç¼ºå¤±å€¼åˆ†æ
        for col in df.columns:
            missing_count = df[col].isnull().sum()
            missing_percentage = (missing_count / len(df)) * 100
            quality['missing_values'][col] = {
                'count': int(missing_count),
                'percentage': float(missing_percentage)
            }
            
            # æ ‡è®°é«˜ç¼ºå¤±ç‡å­—æ®µ
            if missing_percentage > 70:
                quality['potential_issues'].append(f"High missing rate in '{col}': {missing_percentage:.1f}%")
        
        # æ•°æ®ç±»å‹åˆ†æ
        for col in df.columns:
            quality['data_types'][col] = str(df[col].dtype)
        
        # å¼‚å¸¸å€¼æ£€æµ‹
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            series = df[col].dropna()
            if len(series) > 0:
                outliers = self._detect_outliers(series)
                if outliers:
                    quality['potential_issues'].append(f"Outliers detected in '{col}': {len(outliers)} values")
        
        return quality
    
    def _detect_outliers(self, series: pd.Series) -> List[float]:
        """æ£€æµ‹å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰"""
        if len(series) < 4:
            return []
        
        Q1 = series.quantile(0.25)
        Q3 = series.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = series[(series < lower_bound) | (series > upper_bound)].tolist()
        return outliers[:10]  # Limit to first 10 outliers
    
    def _generate_business_insights(self, df: pd.DataFrame) -> List[str]:
        """ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ"""
        insights = []
        
        # æ´»è·ƒåº¦æ´å¯Ÿ
        activity_cols = [col for col in df.columns if 'ç§¯åˆ†äº§ç”Ÿ' in col]
        if activity_cols:
            activity_col = activity_cols[0]
            inactive_ratio = (df[activity_col] == 'æ˜¯').mean() if 'æ˜¯' in df[activity_col].values else 0
            if inactive_ratio > 0.8:
                insights.append(f"ğŸš¨ é«˜ä¸æ´»è·ƒç‡: {inactive_ratio:.1%} çš„ä¼šå‘˜åœ¨è¿‡å»6ä¸ªæœˆå†…æ²¡æœ‰äº§ç”Ÿç§¯åˆ†")
        
        # æ¸ é“æ´å¯Ÿ
        channel_cols = [col for col in df.columns if 'æ¸ é“' in col]
        if channel_cols:
            channel_col = channel_cols[0]
            top_channel = df[channel_col].value_counts().index[0]
            insights.append(f"ğŸª ä¸»è¦è´­ä¹°æ¸ é“: {top_channel}")
        
        # åœ°åŸŸæ´å¯Ÿ
        location_cols = [col for col in df.columns if 'çœ' in col or 'å¸‚' in col]
        if location_cols:
            loc_col = location_cols[0]
            provinces = df[loc_col].astype(str).str.split('çœ', expand=True)[0]
            top_province = provinces.value_counts().index[0]
            insights.append(f"ğŸ“ ä¸»è¦å¸‚åœºåŒºåŸŸ: {top_province}")
        
        # ä¼šå‘˜ç­‰çº§æ´å¯Ÿ
        tier_cols = [col for col in df.columns if 'ç­‰çº§' in col]
        if tier_cols:
            tier_col = tier_cols[0]
            top_tier = df[tier_col].value_counts().index[0]
            top_tier_ratio = df[tier_col].value_counts().iloc[0] / len(df)
            if top_tier_ratio > 0.8:
                insights.append(f"ğŸ† ä¼šå‘˜ç»“æ„é›†ä¸­: {top_tier} ç­‰çº§å  {top_tier_ratio:.1%}")
        
        # æ•°æ®è´¨é‡æ´å¯Ÿ
        high_missing_fields = sum(1 for col in df.columns if df[col].isnull().sum() / len(df) > 0.7)
        if high_missing_fields > 5:
            insights.append(f"âš ï¸ æ•°æ®è´¨é‡é—®é¢˜: {high_missing_fields} ä¸ªå­—æ®µç¼ºå¤±ç‡è¶…è¿‡70%")
        
        return insights