{
  "id": "cortex",
  "kind": "memory",
  "configSchema": {
    "type": "object",
    "additionalProperties": false,
    "properties": {
      "enabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable Cortex memory enhancements"
      },
      "autoCapture": {
        "type": "boolean",
        "default": true,
        "description": "Automatically capture important conversation moments"
      },
      "stmFastPath": {
        "type": "boolean",
        "default": true,
        "description": "Check STM before full memory search (fast path)"
      },
      "temporalRerank": {
        "type": "boolean",
        "default": true,
        "description": "Re-rank search results by recency"
      },
      "temporalWeight": {
        "type": "number",
        "default": 0.4,
        "minimum": 0,
        "maximum": 1,
        "description": "Weight for temporal/recency scoring (0-1)"
      },
      "importanceWeight": {
        "type": "number",
        "default": 0.3,
        "minimum": 0,
        "maximum": 1,
        "description": "Weight for importance scoring (0-1)"
      },
      "stmCapacity": {
        "type": "integer",
        "default": 50000,
        "minimum": 5,
        "maximum": 100000,
        "description": "Maximum items in short-term memory"
      },
      "embeddingsUrl": {
        "type": "string",
        "default": "http://localhost:8030",
        "description": "GPU embeddings daemon URL for memory index"
      },
      "activeSessionCapacity": {
        "type": "integer",
        "default": 50,
        "minimum": 10,
        "maximum": 500,
        "description": "Messages to keep in active session RAM cache"
      },
      "hotTierSize": {
        "type": "integer",
        "default": 100,
        "minimum": 10,
        "maximum": 1000,
        "description": "Phase 2: Number of most-accessed memories to keep in hot tier"
      },
      "maxContextTokens": {
        "type": "integer",
        "default": 1500,
        "minimum": 100,
        "maximum": 10000,
        "description": "Phase 2: Base token budget for memory context (dynamic scaling adds more for complex conversations)"
      },
      "relevanceThreshold": {
        "type": "number",
        "default": 0.5,
        "minimum": 0,
        "maximum": 1,
        "description": "Phase 2: Skip memories below this relevance score"
      },
      "truncateOldMemoriesTo": {
        "type": "integer",
        "default": 180,
        "minimum": 50,
        "maximum": 500,
        "description": "Phase 2: Truncate old memories to this many characters (keeps sentences coherent)"
      },
      "deltaSyncEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Phase 2: Enable background delta sync (every 5 minutes)"
      },
      "prefetchEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Phase 2: Enable predictive category prefetching"
      }
    }
  }
}
